{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Activity 11: Classifying Air Quality Monitoring Sites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will explore a large data set compiled by the US Environmental Protection Agency’s Air Quality System ([EPA AQS](https://aqs.epa.gov/aqsweb/airdata/download_files.html#Annual)), a network of thousands of monitoring sites that measure dozens of meteorological as well as air quality-related variables. These sites can be classified as either “urban” (category 2) or “suburban/rural” (category 1) based on the population of the area in which they are located. \n",
    "\n",
    "In this activity, you will use a computational classification algorithm (specifically, the k-nearest-neighbor algorithm you learned about this morning) to predict a monitoring site’s urban vs. rural classification based on its annually averaged temperature, pressure, ozone, sulfur dioxide, and particulate matter measurements from 2013. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Five-Nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to load the data from 165 sites in 2013. Note that the temperature, pressure, and PM<sub>2.5</sub> quantities reflect the average of 365 daily averages, while the ozone and sulfur dioxide quantities are the average of 365 daily maxima. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the data \n",
    "data = pd.read_csv(\"data/knearest_neighbor_practice.csv\", error_bad_lines=False)\n",
    "\n",
    "# show the first 5 rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.1.1** Begin by normalizing the numerical variables into \"standard units.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE THAT SUBTRACTS OFF THE MEAN AND DIVIDES BY THE STANDARD DEVIATION OF EACH DATA COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.1.2** Use the code below separate the data set into two randomly selected and non-overlapping subgroups: the \"training\" sample and the \"test\" sample. You may choose any size for training sample, but it is best if training sample is at least as large as the test sample, if not much larger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHOOSE HOW MANY SITES YOU WOULD LIKE TO INCLUDE IN YOUR TRAINING SAMPLE\n",
    "training_sample_size = \n",
    "\n",
    "# select a training sample of this size from sites #0-164\n",
    "training_indices = np.random.choice(165,training_sample_size,replace=False)\n",
    "training_indices = np.sort(training_indices)\n",
    "\n",
    "# define test sample as whatever is left\n",
    "all_indices = np.arange(165)\n",
    "test_indices = all_indices[np.logical_not(np.isin(all_indices,training_indices))]\n",
    "test_indices = np.sort(test_indices)\n",
    "\n",
    "# divide up the standardized numerical values according to site numbers chosen for each sample\n",
    "training_data = data_std.iloc[training_indices]\n",
    "test_data = data_std.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample code above used the function \"iloc\" to extract certain values from a dataframe--in this case, all of the values in a certain row. The function \"iat\" works similarly, but has the added benefit that the values, once extracted, are standalone numbers outside of the dataframe format. This means you can do math with the output of the \"iat\" function. Use the code provided below to subtract the value in the first row and column of your training_data from the value in the first row and column of your test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of the first row and column of training_data\n",
    "first_train = training_data.iat[0,0]\n",
    "\n",
    "# get the value of the first row and column of test_data\n",
    "first_test = test_data.iat[0,0]\n",
    "\n",
    "# subtract!\n",
    "first_test - first_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.1.3** Calculate the \"distance\" between each site in your test sample and all of the sites in your training sample based on the differences in their temperature, pressure, ozone, sulfur dioxide, and particulate matter measurements.\n",
    "\n",
    "*Hint: The \"iat\" function you used above will likely come in handy!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty dataframe to hold your distance calculations\n",
    "all_distances = pd.DataFrame()\n",
    "\n",
    "# iterate over each site (row) in your test_data variable\n",
    "for i in np.arange(len(test_indices)):\n",
    "        \n",
    "    ## ENTER CODE HERE TO CALCULATE THE \"DISTANCE\" BETWEEN THIS SITE AND EACH OF THE TRAINING SITES\n",
    "\n",
    "# display the results\n",
    "print(all_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates how to use the function \"nsmallest\" to identify the indices associated with the five smallest numbers in the first row of the \"all_distances\" variable you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first row from the all_distances dataframe\n",
    "first_test_site = all_distances.iloc[0,:]\n",
    "\n",
    "# identify the indices of the five smallest values\n",
    "smallest_indices = first_test_site.nsmallest(5).index\n",
    "\n",
    "# display the result\n",
    "print(smallest_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.1.4** By using the sample code above in a \"for\" loop, identify the \"nearest\" five training sample site neighbors for each test sample site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty dataframe to hold the nearest neighbor indices\n",
    "nearest_neighbors = pd.DataFrame()\n",
    "\n",
    "# interate over each site (row) in your all_distances dataframe\n",
    "for i in np.arange(len(all_distances)):\n",
    "    \n",
    "    ## ENTER CODE HERE TO IDENTIFY WHICH FIVE TRAINING SITES ARE \"NEAREST\" TO THIS TEST SITE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates how to use the scipy function \"stats.mode\" to identify the most common value in a list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary library\n",
    "import scipy.stats\n",
    "\n",
    "# define an example variable containing five hypothetical urban/rural classifications\n",
    "example_classifications = [1,2,2,2,1]\n",
    "\n",
    "# compute and display the mode of the example_classifications variable\n",
    "print(scipy.stats.mode(example_classifications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numerical value of the \"mode array\" can also be saved to its own variable\n",
    "mode = scipy.stats.mode(example_classifications).mode[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.1.5** Predict the urban vs. rural classification of each test sample site based on the most common classification observed among its five nearest training sample neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE THAT PREDICTS THE CLASSIFICATION OF EACH TEST SITE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.2.1** Compare your predicted classifications and the actual urban vs. rural classifications of your test sample sites. Calculate the number of \"true positives\" (predicted \"urban\" and actually \"urban\"), \"false positives\" (predicted \"urban,\" but actually \"rural\"), and \"false negatives\" (predicted \"rural,\" but actually \"urban\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALCULATE THE NUMBER OF TRUE POSITIVES,\n",
    "## FALSE POSITIVES, AND FALSE NEGATIVES IN YOUR PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.2.2** Modify the code below to calculate the \"precision\" and \"recall\" of your classification algorithm based on the names of the variables you defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UPDATE THE VARIABLE NAMES BELOW ACCORDINGLY\n",
    "precision = true_pos / ( true_pos + false_pos )\n",
    "recall = true_pos / ( true_pos + false_neg )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the code below to calculate the cumulative F<sub>1</sub> score for your classification algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = 2 * ( precision * recall ) / ( precision + recall )\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.2.3** Given the definitions of the various metrics above, is it more desirable to have a high F<sub>1</sub> score or a low F<sub>1</sub> score?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Classification Using Other K Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.3.1** Re-write your original algorithm two more times, each time using a different number of nearest neighbors to determine the classification of your test sample sites.\n",
    "\n",
    "*Hint: You should always use an odd number of neighbors! Why?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE THAT PREDICTS URBAN/RURAL CLASSIFICATION BASED ON A DIFFERENT NUMBER OF NEIGHBORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE THAT PREDICTS URBAN/RURAL CLASSIFICATION again BASED ON yet another DIFFERENT NUMBER OF NEIGHBORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.3.2** Calculate the recall, precision, and F<sub>1</sub> score for your two new classification algorithms as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE THAT EVALUATES THE PERFORMANCE OF YOUR NEW CLASSIFICATION ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.3.3** How many neighbors were used in the algorithm with the optimal F<sub>1</sub> score?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Classification Using Fewer Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.4.1** Although you were given five numerical variables upon which to base your classification, you do not necessarily need to incorporate all five into your algorithm. Think about what each of these variables actually represent in the physical world–do all seem equally related to a site's urban vs. rural classification? \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.4.2** Choose a two- to four-variable subset of the original five and re-write your classification algorithm using only this subset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE THAT PREDICTS URBAN/RURAL CLASSIFICATION BASED ON FEWER VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.4.3** Did your F<sub>1</sub> score improve? What does this say about your hypothesis regarding the relationship between certain variables and the urban vs. rural classification?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Questions.** Pair up with a partner and discuss the following:\n",
    "\n",
    "1. Compare the F<sub>1</sub> scores of your original, five-variable classification algorithms. \n",
    "    * What was the optimal number of neighbors used by either you or your partner?\n",
    "    * Did you both use the same size of training vs. test samples? Which sample size resulted in the superior F<sub>1</sub> score for the original, five-neighbor algorithm?\n",
    "    * What seems to be the general relationship between training sample size and algorithm performance? You should modify and re-run your algorithm a few times to help support your answer.\n",
    "    * Notice that your F<sub>1</sub> score changes slightly every time you re-run your algorithm, even when you do not change any of the parameters. This is due to a new random selection of sites for the training vs. test samples. How many runs of a given algorithm configuration would you need to feel confident that you have characterized its performance relative to another algorithm?\n",
    "2. The “urban” vs. “suburban/rural” classifications in this data set were made based on the population of the “[Core Based Statistical Area](https://en.wikipedia.org/wiki/Core-based_statistical_area)” in which the monitoring site is located. Knowing this definition, what factors might confound the relationship between a site’s classification and its meteorological and/or air quality measurements? What might this mean for the maximum efficacy your classification algorithm can ultimately achieve?\n",
    "3. Given that the US Environmental Protection Agency knows the actual location of each of its air quality monitoring sites, there are probably easier ways to determine their urban vs. rural classification than applying an algorithm to their annual air quality metrics. Can you think of an atmospheric science question for which an effective classification algorithm would be more directly useful?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answers here.]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
