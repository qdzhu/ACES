{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Activity 1: Introduction to Atmospheric Data Analysis\n",
    "\n",
    "__1.1 Creating a Time Series__\n",
    "\n",
    "Examine the monthly CO<sub>2</sub> mixing ratios measured at Mauna Loa (Hawaii, USA), Pt. Barrow (Alaska, USA), and the South Pole (Antarctica) during 2013:\n",
    "\n",
    "|Site|Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|\n",
    "|--- |--- |--- |--- |--- |--- |--- |--- |--- |--- |--- |--- |--- |\n",
    "|MLO|399.55|396.80|397.43|398.41|399.78|398.61|397.32|395.20|393.45|393.70|395.16|396.84|\n",
    "|PTB|401.09|402.35|403.00|402.32|403.27|400.80|390.00|387.26|388.63|395.22|399.59|403.77|\n",
    "|SPO|391.19|391.26|391.31|391.71|392.32|392.82|393.36|393.91|394.08|394.03|394.03|394.07|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.1** Create lists called \"MLO_CO2\", \"PTB_CO2\", and \"SPO_CO2\" containing the mixing ratio data. A list called \"months\" has been created for you with the names of each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of months to be used to identify each column in our data\n",
    "months=[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of CO2 measurements for each site\n",
    "MLO_CO2= ## ENTER CODE HERE TO ADD DATA TO MLO_CO2 VARIABLE\n",
    "PTB_CO2= ## ENTER CODE HERE TO ADD DATA TO PTB_CO2 VARIABLE\n",
    "SPO_CO2= ## ENTER CODE HERE TO ADD DATA TO SPO_CO2 VARIABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.2** Add code to the field below to make a line graph of how the CO<sub>2</sub> mixing ratios at these three sites change over time. The necessary functions have already been imported for you and the MLO_CO2 variable has already been plotted as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# first install the graphing library\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the graphing library for the first time with the abbrviated name 'plt'\n",
    "import matplotlib.pyplot as plt\n",
    "# from the matplotlib library import 'figure' so we can play with subplots\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# create a subplot instance and store referenes to the figure and axis\n",
    "# this particular subplot has a 'w'hite background and a blac'k' edge around it\n",
    "fig, ax = plt.subplots(num=None, facecolor='w', edgecolor='k')\n",
    "\n",
    "# add data to the 'plt' using the plot function defining the x and y data\n",
    "ax.plot(months, MLO_CO2, linewidth=2, label='Mauna Loa (Hawaii, USA)')\n",
    "## ENTER CODE HERE TO PLOT PTB_CO2 TIME SERIES\n",
    "## ENTER CODE HERE TO PLOT SPO_CO2 TIME SERIES\n",
    "\n",
    "# The graphing library calling functions to set title and labels\n",
    "# to find out more fun functions see: https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.html\n",
    "plt.title('CO2 mixing ratios in 2013')\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('CO2')\n",
    "\n",
    "#add a legend\n",
    "fig.legend(bbox_to_anchor=(1, 0.9),bbox_transform=plt.gcf().transFigure)\n",
    "\n",
    "#show the final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph you made above is called a \"time series\" because it shows the change in a data series over time. Although one of the simplest forms of data analysis, time series can be very powerful in that they reveal patterns and invite comparisons between numerical data. Examine your time series closely.\n",
    "\n",
    "**Question 1.1.3** During which month is the minimum CO<sub>2</sub> concentration observed at each site? Why do you think that is?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.4** Compare the magnitude of variation in CO<sub>2</sub> concentrations at each site. What do you think is responsible for these differences in variability?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine some larger datasets of CO<sub>2</sub> mixing ratios measured at College Preparatory School, Kaiser Center, and Fred T. Korematsu Elementary School (all right here in the Bay Area!) during 2013. The code below imports the data from a website, places it in an easy-to-use format called a \"dataframe,\" and reconfigures the associated timestamps.\n",
    "\n",
    "Even though a large quantity of code has been provided for you, make sure to read through each line and the associated comments so that you understand what each part does. When you need to do perform similar actions in the future, you will refer back to this example code as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# first install libraries for loading and manipulating data\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the loading and data manipulation libraies for the first time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# declare a variable called 'url' to be used for the API to access data over the internet\n",
    "# for more information on this dataset visit: http://beacon.berkeley.edu\n",
    "url = \"http://beacon.berkeley.edu/node/37,54,31/measurements/csv?name=Multiselect%20Download&interval=60&start=2013-02-01%2000:00:00&end=2013-12-31%2000:00:00\"\n",
    "\n",
    "# load the comma delimited data into a dataframe using pandas\n",
    "CO2_2013_data  = pd.read_csv(url)\n",
    "\n",
    "# note: each node is identified by a node_id in the file\n",
    "# College Preparatory School is 37\n",
    "# Kaiser Center is 54 \n",
    "# Fred T. Korematsu Elementary School is 31\n",
    "\n",
    "# create column in the dataframe called 'timestamp' using the 'local_timestamp' column \n",
    "# and teach the program to treat it as a date object using a date format mask\n",
    "CO2_2013_data['timestamp']=pd.to_datetime(CO2_2013_data['local_timestamp'],format='%Y-%m-%d  %H:%M:%S')\n",
    "\n",
    "# now set the 'timestamp' column to be the index of each row\n",
    "CO2_2013_data.index=CO2_2013_data['timestamp']\n",
    "\n",
    "# cleanup our dataframe by removing unneeded columns\n",
    "CO2_2013_data=CO2_2013_data.drop(['local_timestamp','datetime','PM_ug/m3_37','PM_ug/m3_54','PM_ug/m3_31'],axis=1)\n",
    "\n",
    "# replace any -999 data (which flags bad data) with a special value for 'not a number' (NaN)\n",
    "CO2_2013_data = CO2_2013_data.replace(-999,np.NaN)\n",
    "\n",
    "# remove all the rows with NaN values as they won't help our comparison\n",
    "CO2_2013_data.dropna(inplace=True)\n",
    "\n",
    "# print the first 10 lines of data to see what we're working with\n",
    "CO2_2013_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable \"CO2_2013_data\" created above is a \"list of lists\" known as a dataframe containing the CO<sub>2</sub> mixing ratios for the three sites mentioned above, as well as the associated timestamps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.5** Extract the mixing ratios for each site as a separate variable. Also extract a variable containing the \"julian_day\" column. As an example, the variable containing the College Preparatory School (CPS) data have been created for you.\n",
    "\n",
    "*Hint: You may need to consult the comments in the code block above to know which site is which!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPS_CO2=CO2_2013_data['CO2_ppm_37']\n",
    "KC_CO2= ## ENTER CODE HERE TO EXTRACT KAISER CENTER MIXING RATIOS\n",
    "FTK_CO2= ## ENTER CODE HERE TO EXTRACT FRED T. KOREMATSU MIXING RATIOS\n",
    "julian_day= ## ENTER CODE HERE TO EXTRACT JULIAN DAY VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Julian day is a common timestamping convention in which the portion to the left of the decimal tells you the day of the year and the portion to the right of the decimal tells you the fraction of said day that has elapsed. A julian_day = 3.5, for example, would coincide to noon on 3 January, while julian_day = 218.25 would correspond to 6am on 6 August (in a non-leap year).\n",
    "\n",
    "A helpful table of Julian day values can be found [here](https://landweb.modaps.eosdis.nasa.gov/browse/calendar.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.6** Plot a time series of the three sites' mixing ratios below using 'julian_day' as the x variable. Consult the example code you used to graph the monthly CO<sub>2</sub> mixing ratios you encountered earlier in this activity as a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO GENERATE TIME SERIES OF HOURLY BAY AREA MIXING RATIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.2 Analyzing Correlations__\n",
    "\n",
    "While examining the similarities and differences between two time series by eye can be very informative, sometimes a more direct comparison is called for. We can analyze the correlation between two variables by plotting one as a function of another in a graph called a \"scatter\" plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates how to make a scatter plot showing the CO<sub>2</sub> mixing ratio measured at College Preparatory School as a function of that measured at Fred T. Korematsu Elementary School."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example comparing College Preparatory School to Fred T. Korematsu School using a scatter plot\n",
    "plt.scatter(CPS_CO2, FTK_CO2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plotting correlations, it is often helpful to add a line that depicts what a perfect 1 to 1 relationship between the two variables would look like. The code below accomplishes this task; read through the code and the associated comments to make sure you understand how it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules 'lines' as 'mlines' and 'transforms' as 'mtransforms' from the matplotlib library for use in creating the 1 to 1 line\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "# using suplots again allows us to easily plot additional information in the same plot\n",
    "# we keep reference to the axis as 'ax' for later use\n",
    "fig, ax = plt.subplots(num=None, facecolor='w', edgecolor='k')\n",
    "\n",
    "# compare College Preparatory School to Fred. T Korematsu Elementary using a scatter plot added to the 'ax' instance directly\n",
    "ax.scatter(CPS_CO2, FTK_CO2)\n",
    "\n",
    "# add a red 1 to 1 line\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='red')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.1** Practice this process yourself by making a scatter plot showing the CO<sub>2</sub> mixing ratio measured at the Kaiser Center as a function of that measured at Fred T. Korematsu Elementary School. Include a red 1:1 line on your scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT KAISER CENTER MIXING RATIOS AS A FUNCTION OF FRED T. KOREMATSU ELEMENTARY MIXING RATIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also assess the degree of correlation between two variables mathematically. There are many ways of doing this, each with their own strengths and weaknesses depending on the assumptions being made. A common metric is the \"coefficient of determination\" or R<sup>2</sup> value. R<sup>2</sup> values close to 1 indicate a strong relationship between the two variables, while values closer to 0 indicate less correlation.\n",
    "\n",
    "A sample R<sup>2</sup> calculation for the correlation between mixing ratios at College Preparatory School and Fred T. Korematsu Elementary School is shown below. It requires loading a special library of statistical functions called \"sklearn.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# install the sklearn module built on top of scipy for machine learning\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the r2_score module for use in calculating the \"coefficient of determination\" or 'r squared'\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# calculate the 'r squared' between College Preparatory School and Fred T. Korematsu Elementary School\n",
    "print(r2_score( CPS_CO2, FTK_CO2,  multioutput='variance_weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.2** Practice calculating your own R<sup>2</sup> values for: \n",
    "\n",
    "(1) the correlation between the College Preparatory School data record and the Kaiser Center mixing ratios, and \n",
    "\n",
    "(2) the correlation between the Fred T. Korematsu Elementary School data record and the Kaiser Center mixing ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALCULATE R2 BETWEEN CPS AND KC MIXING RATIOS \n",
    "\n",
    "## ENTER CODE HERE TO CALCULATE R2 BETWEEN FTK AND KC MIXING RATIOS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.3** Based on the R<sup>2</sup> values, which two datasets appear to be the most tightly correlated?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even without these numerical metrics, we can tell visually that these datasets are strongly correlated (in that their correlation plots are clustered around the 1 to 1 line) but with a fair amount of \"scatter\" (in that a large proportion of points do not fall precisely on the 1 to 1 line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.3 Averaging and Smoothing__\n",
    "\n",
    "The CO<sub>2</sub> mixing ratios analyzed in the previous section were presented at 1 hour resolution. The \"scatter\" observed in the correlation could be feasibly attributed to short-term variations in CO<sub>2</sub> specific to each site, while perhaps longer term variations are shared across all sites. To test this hypothesis, we calculate the *monthly* average CO<sub>2</sub> mixing ratio at the College Preparatory School. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the groupby function of the dataframe allows us to easily group by month using 'M'\n",
    "CO2_2013_data_grouped = CO2_2013_data.groupby(pd.Grouper(freq='M'))\n",
    "\n",
    "# taking the mean of the grouped variable allows us to access the CO2 measurements over the month as one averaged value\n",
    "CO2_2013_data_grouped_avg=CO2_2013_data_grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check our work by plotting the hour data and monthly time series on the same graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using suplots again to plot additional information in the same plot\n",
    "fig, ax = plt.subplots(num=None, facecolor='w', edgecolor='k')\n",
    "\n",
    "# add the hourly 'julian_day' and CPS_CO2 values to the x and y axis\n",
    "ax.plot( CO2_2013_data['julian_day'], CPS_CO2,linewidth=.5,label='College Preparatory School Day')\n",
    "\n",
    "# add the monthly 'julian_day' and CPS_CO2 values to the x and y axis\n",
    "ax.plot( CO2_2013_data_grouped_avg['julian_day'], CO2_2013_data_grouped_avg['CO2_ppm_37'],linewidth=3,label='College Preparatory School Month')\n",
    "\n",
    "# add labels\n",
    "plt.xlabel('Julian Day')\n",
    "plt.ylabel('CO2')\n",
    "plt.title('BEACON CO2 mixing ratios in 2013 monthly average vs day')\n",
    "#add a legend with adjusted position\n",
    "fig.legend(bbox_to_anchor=(1, 0.9),bbox_transform=plt.gcf().transFigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we do not in fact need to extract the hourly (or monthly) CO<sub>2</sub> mixing ratios as separate variables in order to plot them; we can reference the columns of the dataframe directly in our plotting code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.1** Practice this yourself by plotting monthly CO<sub>2</sub> mixing ratios at the Kaiser Center and Fred T. Korematsu Elementary School and checking your work with two time series graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT HOURLY & MONTHLY KC MIXING RATIOS \n",
    "\n",
    "## ENTER CODE HERE TO PLOT HOURLY & MONTHLY LES MIXING RATIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.2** Use your scatter plotting skills from section 1.2 to examine the correlation observed at one-month resolution by plotting the monthly average CO<sub>2</sub> mixing ratios measured at College Preparatory School as a function of the monthly average mixing ratios measured at Fred T. Korematsu Elementary School. Don't forget your red 1:1 line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT MONTHLY CPS MIXING RATIOS vs. MONTHLY LES MIXING RATIOS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.3** Compared to the one-hour correlation you analyzed in the last section, does the correlation seem to be stronger or weaker at the hourly temporal resolution?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that one downside of this averaging technique is that you end up with fewer data points in each dataset. In order to minimize the impact of short-term local variations while still preserving the original size of the dataset, a \"smoothing\" approach is sometimes preferred. Smoothing involves using a moving \"window\" to calculate an average for every time step of the original dataset, as shown below using a one-month window to smooth the College Preparatory School mixing ratios. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a variable for the number of hours to smooth by\n",
    "hours_per_month=str(30*24)+'h'\n",
    "\n",
    "# create a moving-average using the number of hours specified\n",
    "# this requires moving the 'timestamp' column into the index position if it isn't already\n",
    "CO2_2013_data_moving_avg=CO2_2013_data.set_index('timestamp').rolling(hours_per_month).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the averaging and smoothing approaches by plotting the two time series on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num=None, facecolor='w', edgecolor='k')\n",
    "ax.plot( CO2_2013_data_grouped_avg['julian_day'], CO2_2013_data_grouped_avg['CO2_ppm_37'],linewidth=2,label='College Preparatory School Month Avg')\n",
    "ax.plot( CO2_2013_data_moving_avg['julian_day'], CO2_2013_data_moving_avg['CO2_ppm_37'],linewidth=2,label='College Preparatory School Moving Window Monthly Avg')\n",
    "\n",
    "plt.xlabel('Julian Day')\n",
    "plt.ylabel('CO2')\n",
    "plt.title('CO2 mixing ratios in 2013, College Preparatory School, moving window vs. monthly average')\n",
    "#add a legend with adjusted position\n",
    "fig.legend(bbox_to_anchor=(1, 0.9),bbox_transform=plt.gcf().transFigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.4** Practice this yourself by plotting the smoothed CO<sub>2</sub> mixing ratios at the Kaiser Center and Fred T. Korematsu Elementary School using a moving one-month window. Compare the smoothed and monthly-averaged data products by making two graphs with two time series each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT MONTHLY SMOOTHED & AVERAGED KC MIXING RATIOS \n",
    "\n",
    "## ENTER CODE HERE TO PLOT MONTHLY SMOOTHED & AVERAGED FTK MIXING RATIOS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.5** Practice your averaging and smoothing skills one more time by choosing a different time window to try (e.g. daily, weekly, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student's choice :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.4 Analyzing Temporal Patterns__\n",
    "\n",
    "Now that you have mastered the art of averaging, you can apply it in more complex ways. Longitudinal datasets like the Bay Area CO<sub>2</sub> mixing ratios you have been working with are invaluable for documenting long-term trends, but they also provide statistically robust records of repeating, short-term phenomena. A classic example of the latter is the 24-hour cycle in mixing ratios that results from regular changes in meteorology and emissions patterns associated with different times of day (e.g., sunrise, rush hour traffic, sunset, etc.). Known as the \"diel cycle,\" understanding this 24-hour pattern gives rich information about the complex interplay of these underlying factors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe you have been using to house the hourly CO<sub>2</sub> data provides a convenient shortcut for averaging the data collected at 1am, 2am, etc. as shown in the sample code below. Note that this is a different method of using the \"grouby\" function. Notice how this changes the datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO2_2013_data_grouped_diel=CO2_2013_data.groupby(CO2_2013_data.index.hour).mean()\n",
    "\n",
    "print(CO2_2013_data_grouped_diel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.1** Using the \"grouped\" means generated above, plot the diel cycle in CO<sub>2</sub> mixing ratios measured at the three Bay Area sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT DIEL CYCLE IN CPS, KC, AND FTK MIXING RATIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.2** When do the highest CO<sub>2</sub> concentrations occur at each site? When do the lowest concentrations occur? Offer a possible explanation for the timing of these maxima and minima and the site-to-site differences."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[ Enter your answer here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another commonly examined temporal pattern is the weekly cycle comparing concentrations observed on Mondays to those measured on Tuesdays, Wednesdays, etc. Since all meteorological patterns are equally likely to occur on all days, the weekly cycle singles out phenomena associated with changes in human behavior (e.g., morning rush hour on weekdays vs. weekend traffic patterns). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.3** Devise a strategy for calculating and plotting the weekly cycle in CO<sub>2</sub> mixing ratios measured at the three Bay Area sites.\n",
    "\n",
    "*Hint: Consult the documentation for the \"[Datetime Index](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DatetimeIndex.html)\" to determine the appropriate modification to the hour-based \"groupby\" example given above. You may also be interested in referencing [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.between_time.html) to select data at or between certain times of the day*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALCULATE AND PRINT MIXING RATIOS AVERAGED BY DAY OF WEEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT THE WEEKLY CYCLE IN CPS, KC, AND LES MIXING RATIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Questions.** Pair up with a partner and discuss the following:\n",
    "\n",
    "1. What time(s) of day did you include in your weekly cycle analysis? Why? \n",
    "2. Repeat your analysis including different time(s) of day. What seem to be the benefits and drawbacks of your original approach compared to this new one?\n",
    "3. Day of week analyses are sometimes simplified as a binary \"weekday\" vs. \"weekend\" comparison. Of course, one of these two categories will end up with many more data points than the other! If you were to exclude one day of the week from the \"weekday\" category, what day would you choose and why?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
