{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Activity 12: Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*adapted from Machine Learning by Andrew Ng*\n",
    "\n",
    "*see also: https://www.johnwittenauer.net/machine-learning-exercises-in-python-part-8/*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a hypothetical monitoring network consisting of 614 low-cost sensor nodes measuring ozone and temperature. While it is often possible to identify failing sensors by visual inspection of their data output, this task becomes impractical with a network of this size, especially given the natural variability in atmospheric conditions across a network domain. \n",
    "\n",
    "Today you will design a classification algorithm that flags possible sensor failures by detecting nodes with anomalous data. The population of nodes has already been divided into two equal halves to form a \"training\" set and a \"test\" set. The training set has been manually screened and the failed sensors labeled as anomalies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Anomaly Detection Using Two Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to load the ozone and temperature readings from the sensors in the \"test\" set. The data matrix should have a \"shape\" of 307 by 2, corresponding to one observation of each variable made by half of the sensor nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary library\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# load the ozone and temperature readings\n",
    "data = loadmat('data/anomaly_practice_1.mat')\n",
    "test_data = data['X']\n",
    "\n",
    "# display the variables \"shape\"\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.1.1** Determine the Gaussian distributions most representative of the ozone and temperature values in the test data by computing the mean and variance of these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO COMPUTE TWO MEANS AND TWO VARIANCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.1.2** The function shown below will calculate the probability that a data point belongs to a given multivariate normal distribution. Update the variable names in this code so that it correctly calculates the probability that each of the sensor nodes in your test data set belongs to the normal distributions defined by the means and variances of the ozone and temperature distributions you calculated above. Your final probability data matrix should have a \"shape\" of 307 by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary library\n",
    "from scipy import stats\n",
    "\n",
    "# generate a normal distribution based on the calculated means and variances\n",
    "## UPDATE THIS CODE TO REFLECT THE VARIABLE NAMES YOU USED IN Q12.1.2 AS NECESSARY\n",
    "dist = stats.multivariate_normal(means, variances)\n",
    "\n",
    "# calculate the probabily that the test data belongs to this normal distribution\n",
    "prob = dist.pdf(test_data)\n",
    "\n",
    "# display the shape of the probability variable\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how probable it is that each data point belongs to the normal distributions of ozone and temperature readings characterized by the test data set and can use this information to identify sensor nodes exhibiting anomalous behavior (i.e., those whose ozone and/or temperature readings have a lower probability of belonging to the normal distribution(s)). The remaining question is: what probability threshold should you use as the boundary between anomalies and non-anomalies?\n",
    "\n",
    "This is where the \"training\" data set becomes useful! Use the code below to load  the ozone and temperature readings from the sensors in the training set, as well as the quality \"flags\" that have already been assigned to those sensors. Anomalous sensors are assigned a flag of \"1;\" all other sensors are assigned a flag of \"0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data['Xval']\n",
    "train_labels = data['yval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.1.3** Make a scatter plot of the training data and use the training labels to color the markers to verify visually that the proper sensors have been flagged as anomalous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CREATE A SCATTER PLOT OF THE TRAINING DATA\n",
    "## COLORED BY QUALITY FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the sites that we would ideally like to be able to detect using our probability distrbution function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.1.4** To get started, calculate the probability that each sensor node from the *training* data set belongs to the multivariate normal distribution defined by the means and variances of the *test* data set. Then make a scatter plot of the probabilities to get a sense of the range of magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALCULATE THE PROBABILIY THAT THE TRAINING DATA\n",
    "## BELONGS TO THE TEST DATA'S NORMAL DISTRIBUTION\n",
    "\n",
    "## ENTER CODE HERE TO PLOT THE PROBABILITIES CALCULATED ABOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.1.5** Next, write code that loops over a range of possible threshold probabilities and uses each threshold to classify the data points in the training set. The code should also compare this probability-based classification to the true labels and calculate the number of true positives, false positives, and false negatives. Together, these metrics can be used to compute the “F<sub>1</sub>” score of the classification. \n",
    "\n",
    "*Hint 1: Consult Activity 11 for the definitions of true positives, false positives, false negatives, precision, recall, and F<sub>1</sub> scores.*\n",
    "\n",
    "*Hint 2: You should only examine threshold probabilities that actually result in some anomalous flags. Otherwise, you will end up with no true positives and no false positives and you cannot divide by zero!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CLASSIFY THE TRAINING SENSORS BASED ON DIFFERENT THRESHOLD PROBABILITIES\n",
    "\n",
    "## ALSO INCLUDE CALCULATIONS OF TRUE POSITIVES, FALSE POSITIVES, FALSE NEGATIVES\n",
    "## PRECISION, RECALL, AND F1 SCORES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.1.6** Find the threshold probability that resulted in the highest F<sub>1</sub> score. If there are multiple threshold probabilities that result in the same maximum F<sub>1</sub> score, choose the highest threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALCULATE THE HIGHEST F1 SCORE\n",
    "## AND DETERMINE THE CORRESPONDING THRESHOLD PROBABILITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.1.7** Once you have identified the optimal probability threshold, use it to identify anomalous nodes in the test data set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CLASSIFY TEST SENSORS BASED ON THE\n",
    "## THRESHOLD PROBABILITY IDENTIFIED ABOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.1.8** Make a scatter plot of the test data and use the new labels you generated to color the markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CREATE A SCATTER PLOT OF THE TEST DATA\n",
    "## COLORED BY QUALITY FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Anomaly Detection Using 11 Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, you used a combination of two variables to detect anomalous node behavior in a hypothetical monitoring network. Consider another network consisting of 1100 nodes, each measuring 11 different variables. This time your \"training\" set consists of 100 pre-labeled nodes and your \"test\" set consists of the remaining 1000. Use the code below to load the necessary data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "data = loadmat('data/anomaly_practice_2.mat')\n",
    "test_data = data['X']\n",
    "train_data = data['Xval']\n",
    "train_labels = data['yval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.2.1** Repeat the procedure from the 2-variable example above to: (1) characterize the multivariate normal distribution that describes the 11 variables of the test data set, (2) select the threshold probability that maximizes the F<sub>1</sub> score of the classification of the training data set, and (3) apply the threshold probability to detect anomalies in the test data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO COMPUTE 11 MEANS AND 11 VARIANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALCULATE THE PROBABILIY THAT THE TRAINING DATA\n",
    "## BELONGS TO THE TEST DATA'S NORMAL DISTRIBUTION\n",
    "\n",
    "## ENTER CODE HERE TO PLOT THE PROBABILITIES CALCULATED ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CLASSIFY THE TRAINING SENSORS BASED ON DIFFERENT THRESHOLD PROBABILITIES\n",
    "\n",
    "## ALSO INCLUDE CALCULATIONS OF TRUE POSITIVES, FALSE POSITIVES, FALSE NEGATIVES\n",
    "## PRECISION, RECALL, AND F1 SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALCULATE THE HIGHEST F1 SCORE\n",
    "## AND DETERMINE THE CORRESPONDING THRESHOLD PROBABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CLASSIFY TEST SENSORS BASED ON THE\n",
    "## THRESHOLD PROBABILITY IDENTIFIED ABOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Questions.** Pair up with a partner and discuss the following:\n",
    "\n",
    "1. When you visualized the anomalous nodes in your 2-variable test data set, were you satisfied with your anomaly detection algorithm? Why or why not?\n",
    "    * How might you visualize the performance of your 11-variable classifier?\n",
    "2. Compare your F<sub>1</sub> score, threshold probability, and number of anomalous nodes detected for both the 2-variable and 11-variable examples with those calculated by your partner. If there are differences, discuss some possible reasons why. If they are largely similar, discuss some assumptions or decisions you could have made differently that might have led to a different answer.\n",
    "3. Consider the real, physical phenomena that this hypothetical scenario represents.\n",
    "    * What might cause a node to simultaneously report an anomalous temperature and anomalous ozone reading?\n",
    "    * What might cause a node to report 11 anomalous variables simultaneously? Does it matter what the other 9 variables are?\n",
    "    * Outside of this hypothetical example, are there other types of sensor failure that your algorithm might miss? How might you propose to incorporate those scenarios into your algorithm?\n",
    "4. When you performed the k-nearest-neighbor classification yesterday, you normalized the units of each parameter before calculating the distances between points. In today’s anomaly classification exercise, you did not normalize the units beforehand. Was this a justifiable approach? Why or why not?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answers here.]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
