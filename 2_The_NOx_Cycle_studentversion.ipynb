{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Activity 2: Working with N/O<sub>x</sub> Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will explore measurements of nitrogen oxides collected during a large-scale aircraft campaign that took place over South Korea and the surrounding areas from April to June 2016. The project was named “KORUS-AQ” to commemorate the collaborative effort of Korean and United States institutions to characterize a number of different air quality-relevant atmospheric species around Korea.\n",
    "\n",
    "The National Aeronautics and Space Administration (NASA) maintains the datasets for the KORUS-AQ campaign in a standardized format called \"ICARTT,\" which stands \"International Consortium for Atmospheric Research on Transport and Transformation.\" The python3 programming language does not know how to interpret ICARTT files by default, so we have provided a function that handles these files for you. This is a function you can return to if you encounter ICARTT files again in the future.\n",
    "\n",
    "Run the code below to define the function within this jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first install the necessary libraries\n",
    "from urllib.request import urlopen \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frame(_url):\n",
    "    header_line = None\n",
    "    header=None\n",
    "    data=[]\n",
    "\n",
    "    # download the data from the internet\n",
    "    req = urlopen(_url)\n",
    "\n",
    "    # loop over each of the lines in the file\n",
    "    for i, line in enumerate(req):\n",
    "        \n",
    "        # for each line treat it as utf-8, remove line breaks and return characters. \n",
    "        # then turn it into a list by splitting on commas\n",
    "        l=line.decode('utf-8').replace('\\n', '').replace('\\r', '').split(\",\")\n",
    "        \n",
    "        # the first line indicates how many lines until the data header \n",
    "        if not header_line:\n",
    "                header_line = int(l[0])-1\n",
    "        \n",
    "        # when we reach the 'header_line' (the line that indicates what the columns contain), store it as 'header'\n",
    "        if i == header_line:\n",
    "               header = [s.strip() for s in l]\n",
    "        \n",
    "        # otherwise - if we're past the header, store the data as a float value\n",
    "        elif i>header_line:\n",
    "            try:\n",
    "              data.append([float(n) for n in l])\n",
    "            except:\n",
    "              print(l)\n",
    "           \n",
    "    return pd.DataFrame(data, columns = header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Removing Outliers and Other Non-Physical Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During KORUS-AQ, NO<sub>2</sub> was measured by multiple research teams via multiple instrumentation techniques simultaneously, producing independent datasets that can be used to validate and corroborate one another. Use the code provided below to load the measurements record by three separate instruments on 10 May 2016. Since you are downloading the data directly from the NASA website, this may take a few minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From the website\n",
    "https://www-air.larc.nasa.gov/cgi-bin/ArcView/korusaq\n",
    "Download the following ICartt files\n",
    "Note: these urls were collected by right clicking the web links and copying them\n",
    "\n",
    "\"\"\"\n",
    "# KORUSAQ-NOxyO3_DC8_20160510_R1.ict\n",
    "CHEMI_url = 'https://www-air.larc.nasa.gov/cgi-bin/enzFile?c1684C5749C53F525A470B4E964F4D05ABA2f7075622d6169722f4b4f52555341512f4443385f41495243524146542f5745494e4845494d45522e414e445245572f4b4f52555341512d4e4f78794f335f4443385f32303136303531305f52312e696374'\n",
    "\n",
    "# korusaq-TDLIF-NO2_DC8_20160510_R1.ict\t\n",
    "TDLIF_url ='https://www-air.larc.nasa.gov/cgi-bin/enzFile?c1684C5749C53F525A470B4E964F4D05ABA2f7075622d6169722f4b4f52555341512f4443385f41495243524146542f434f48454e2e524f4e414c442f6b6f72757361712d54444c49462d4e4f325f4443385f32303136303531305f52312e696374'\n",
    "      \n",
    "# KORUSAQ-K-ACES_DC8_20160510_R1.ict\n",
    "KACES_url = 'https://www-air.larc.nasa.gov/cgi-bin/enzFile?c1684C5749C53F525A470B4E964F4D05ABA2f7075622d6169722f4b4f52555341512f4443385f41495243524146542f4d494e2e4b59554e472d45554e2f4b4f52555341512d4b2d414345535f4443385f32303136303531305f52312e696374'\n",
    "\n",
    "#load all the files and store for future use\n",
    "CHEMI_df=get_data_frame(CHEMI_url)\n",
    "TDLIF_df=get_data_frame(TDLIF_url)\n",
    "KACES_df= get_data_frame(KACES_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to view the first five rows of the CHEMI_df, TDLIF_df, and KACES_df dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEMI_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDLIF_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KACES_df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.1** Based on the variable names provided in the header of the dataframes, what is the name of the column that corresponds to the NO<sub>2</sub> measurement in each dataframe? What is the name of the column that corresponds to the timestamp information? Do these columns have the same names in each dataframe?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.2** Visualize these three datasets by plotting their time series on the same graph.\n",
    "\n",
    "*Hint: If you don't remember how to plot a time series, consult Exploratory Activity 1.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first install the necessary graphing library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT THREE NO2 TIME SERIES ON SAME GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.3** What do you notice? Are there any data points that seem “non-physical,” or are unlikely to correspond to actual NO<sub>2</sub> concentrations in the atmosphere?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these \"non-physical\" or \"flat line\" data points are known as \"fill values,\" which are used as place holders when an observation is missing or has been discarded for some reason. For example, the \"CHEMI\" dataset uses the number -999999.90 as its a fill value. For visualization purposes, fill values are often replaced with NaNs, which stands for \"not a number.\"\n",
    "\n",
    "**Question 2.1.4** Replace the fill values in the three NO<sub>2</sub> datasets with NaNs and check your work by re-plotting the same time series from above. The CHEMI fill values have already been replaced as an example; it may take some trial and error to determine the numbers used as fill values in the other two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first install the necessary data manipulation library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEMI_df = CHEMI_df.replace({'NO2_pptv':{-999999.90:np.NaN}})\n",
    "TDLIF_df = ## ENTER CODE HERE TO SET TDLIF FILL VALES TO NANS\n",
    "KACES_df = ## ENTER CODE HERE TO SET TDLIF FILL VALES TO NANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.5** Other than the fill values, are there any other suspect data points that you want to remove from your “cleaned” dataset(s)? If so, devise your own strategy for identifying and removing these “outliers.” Check your work by plotting the new time series. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO REMOVE OTHER OUTLIERS FROM THREE NO2 DATA SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO RE-PLOT \"CLEANED\" NO2 TIME SERIES ON SAME GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Interpolation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.1** You have likely already observed that these three datasets agree remarkably well. Now that the fill values and outliers have been removed, we can examine their agreement more precisely. Plot the KACES NO<sub>2</sub> measurements as a function of the TDLIF NO<sub>2</sub> measurements to analyze their correlation.\n",
    "\n",
    "*Hint: If you don't remember how to make a correlation plot, consult Exploratory Activity 1. If you get an error, keep reading*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO MAKE A SCATTER PLOT OF TDLIF and KACES NO2 DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is likely that you encountered an error when you attempted to create the plot requested above. That is because a correlation can only be plotted for two datasets whose data points perfectly coincide with one another, in this case, in time. The NO<sub>2</sub> mixing ratios in each dataset are associated with slightly different timestamps and so need to be re-processed before their correlation can be plotted.\n",
    "\n",
    "For this purpose, it is helpful to know which measurements were collected the most frequently. Use the code below to ascertain the number of measurements in the KACES and TDLIF lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows in KACES_df\n",
    "KACES_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows in TDLIF_df\n",
    "TDLIF_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this information, you can see that the KACES dataset contains fewer measurements than the TDLIF dataset, implying that the KACES measurements were collected less frequently than the TDLIF measurements. In order to examine the correlation with the TDLIF dataset, use to code below to interpolate the KACES dataset to the proper frequency by predicting what the KACES instrument would have measured during the TDLIF timestamps. Read through the code and comments below carefully to make sure you understand what each line does; you can refer back to this example whenever you need interpolation in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "# create a function that describes the original relationship between the KACES timestamp and NO2 data\n",
    "f_KACES = interpolate.interp1d(KACES_df['Mid_time'],KACES_df['NO2_KACES'],bounds_error=False)\n",
    "\n",
    "# use the function to predict what the KACES instrument would have measured during the TDLIF timestamps\n",
    "NO2_KACES_interp = f_KACES(TDLIF_df['seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.2** Now that you have coincident data, plot the correlations between these datasets. Because you'll be creating many more scatter plots over the course of this activity, define your own function that accepts two datasets as inputs and generates a scatter plot of their correlation that is formatted to your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules 'lines' as 'mlines' and 'transforms' as 'mtransforms' from the matplotlib library for use in creating the 1 to 1 line\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatter_plot(x,y):\n",
    "    \n",
    "    ## ENTER CODE HERE THAT MAKES A SCATTER PLOT OF X vs Y INPUTS\n",
    "    ## YOU MAY WANT TO ADD A 1:1 LINE! CONSULT EXPLORATORY ACTIVITY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALL 'create_scatter_plot' FUCNTION YOU CREATED ABOVE\n",
    "## USE THE ORIGINAL TDLIF NO2 DATA AND THE INTERPOLATED KACES NO2 DATA AS INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.3** Practice this for yourself by instead interpolating the TDLIF dataset onto the KACES frequency and plotting the resulting correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO INTERPOLATE TDLIF NO2 DATA ONTO KACES FREQUENCY AND PLOT RESULTING CORRELATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.4** An alternative to interpolating one dataset onto another’s timestamps is averaging both datasets onto a new, shared frequency. It is best if the new frequency is lower than the approximate frequency of the original datasets. Determine the approximate frquency of the original KACES and TDLIF datasets; are the measurements taken every second, every hour, etc.?\n",
    "\n",
    "Code calculating the frequency of the KACES dataset has been provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the seconds between the first two rows\n",
    "KACES_df_freq=KACES_df.iloc[1][\"Mid_time\"]-KACES_df.iloc[0][\"Mid_time\"]\n",
    "print(\"KACES frequency:\",KACES_df_freq,\"seconds.\")\n",
    "\n",
    "## ENTER CODE HERE TO CALCULATE THE SECONDS BETWEEN THE FIRST TWO ROWS OF THE TDLIF DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.5** Choose a frequency lower than both of those you calculated above to be the new, shared frequency and average both the KACES and TDLIF NO<sub>2</sub> observations to this frequency. Code adding a date column to each dataframe has been provided for you; you should read through the this code carefully and refer back to it whenever you need a date column for averaging in the future.\n",
    "\n",
    "*Hint: If you don't remember how to average data onto new timescales, consult Exploratory Activity 1. It may also be helpful to reference the documentation for the panda \"[Grouper](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Grouper.html)\" function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the datetime library\n",
    "import datetime\n",
    "\n",
    "# add a datetime column to each dataframe\n",
    "TDLIF_df['datetime']=None\n",
    "KACES_df['datetime']=None\n",
    "\n",
    "# define a date variable for use in assigning a date\n",
    "start_date=datetime.datetime.strptime('20160510', '%Y%m%d')\n",
    "\n",
    "# and calculate the new 'datetime' column from the 'Mid_time_UTsec' column -\n",
    "# taking the 'Mid_time_UTsec' column and adding it to the base date\n",
    "for i, row in TDLIF_df.iterrows():\n",
    "    TDLIF_df.at[i, \"datetime\"]=start_date+datetime.timedelta(0,row['seconds'])\n",
    "for i, row in KACES_df.iterrows():\n",
    "    KACES_df.at[i, \"datetime\"]=start_date+datetime.timedelta(0,row['Mid_time'])\n",
    "\n",
    "# set the new datetime columns to be the index of each dataframe\n",
    "TDLIF_df.set_index('datetime', inplace=True, drop=True)\n",
    "KACES_df.set_index('datetime', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDLIF_grouped = ## ENTER CODE HERE TO AVERAGE TDLIF NO2 DATA ONTO A NEW FREQUENCY\n",
    "KACES_grouped = ## ENTER CODE HERE TO AVERAGE KACES NO2 DATA ONTO A NEW FREQUENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're not quite ready to plot the correlation yet because, while they have been averaged to the same frequency, the two dataframes most likely still contain different numbers of observations. Use the code below to \"clip\" off the extra KACES data at the beginning and end of the data record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the value of the first and last entries in the \"datetime\" index column of the TDLIF dataframe\n",
    "first_TDLIF_timestamp = TDLIF_grouped[0:].index[0]\n",
    "last_TDLIF_timestamp = TDLIF_grouped[-1:].index[0]\n",
    "\n",
    "# trim off any \"datetimes\" from the KACES dataframe occuring before the first or after the last TDLIF \"datetime\"\n",
    "KACES_grouped_short = KACES_grouped.truncate(before=first_TDLIF_timestamp,after=last_TDLIF_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.6** Check your work by plotting the correlation of the two new, averaged NO<sub>2</sub> datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALL YOUR 'create_scatter_plot' FUNCTION WITH THE APPROPRIATE INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists an alternate method for unifying disparate datasets built into the pandas dataframe architecture called \"merge.\" Read through the comments and documentation shown below to make sure you understand how this function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html for more information\n",
    "# the \"how='outer'\" parameter allows no data loss by creating rows in the joined table where there is no matching index\n",
    "NO2_df_merge = pd.merge(KACES_df, TDLIF_df, left_on='datetime', right_on='datetime', how='outer')\n",
    "\n",
    "# once the datasets are \"merged,\" you can plot their correlation directly\n",
    "create_scatter_plot(NO2_df_merge['NO2_LIF'],NO2_df_merge['NO2_KACES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to review each of the three correlation strategies above: interpolation, averaging, and merging. Each has its own strengths and weakness. Merging has the benefit that the observations now reside in a single dataframe, and functions can then be easily performed on both datasets simultaneously.\n",
    "\n",
    "As an example, the code below removes rows from the dataframe associated with timestamps containing a NaN value for either the KACES or TDLIF NO<sub>2</sub> observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows containing NaN values in the NO2_KACES column\n",
    "NO2_df_merge=NO2_df_merge.dropna(subset=['NO2_KACES'])\n",
    "\n",
    "# drop rows containing NaN values in the NO2_LIF column\n",
    "NO2_df_merge=NO2_df_merge.dropna(subset=['NO2_LIF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.7** Use the NaN-free merged dataframe to calculate the R<sup>2</sup> value associated with this correlation.\n",
    "\n",
    "*Hint: If you don't remember how to calculate correlation coefficients, consult Exploratory Activity 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the r2_score module for use in calculating the \"coefficient of determination\" or 'r squared'\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "## ENTER CODE HERE TO CALCULATE THE R2 BETWEEN THE TWO NaN-FREE MERGED NO2 DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.8** Now calculate the R<sup>2</sup> value associated with the correlation between interpolated and averaged datasets. Note that you will need to remove the NaN values in those datasets as well; consult the code provided earlier in this exercise for guidance on merging the interpolated and averaged datasets before dropping the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HREE TO MERGE DATAFRAMES, REMOVE NaNs, AND CALCULATE R2 VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 Practicing with Ozone Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been ignoring the CHEMI_df dataset for quite some time! Display the first five lines of this dataframe to remind yourself what it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five lines of the CHEMI_df dataframe\n",
    "CHEMI_df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the \"CHEMI\" instrument is unique from the other two in that it also collected measurements O<sub>3</sub>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.1** Plot the time series of the O<sub>3</sub> mixing ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT A TIME SERIES OF THE O3 MIXING RATIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.2** “Clean” the O<sub>3</sub> data by removing the non-physical “fill values” like you did before for NO<sub>2</sub>. If there are any additional “outliers,” be sure to remove those as well. Check your work by plotting the new time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO REMOVE FILL VALUES AND OTHER OUTLIERS FROM THE O3 DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO PLOT THE \"CLEANED\" O3 DATA SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.3** Create a scatter plot to examine the correlation between the CHEMI NO<sub>2</sub> and O<sub>3</sub> measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO CALL YOUR 'create_scatter_plot' FUNCTION WITH THE APPROPRIATE INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, NO<sub>2</sub> and O<sub>3</sub> don't seem to have a direct 1:1 correlation. To learn more about the nature of their relationship, you can use a linear regression function. The code below demonstrates how to find and plot the line of best fit through these data points. Read through the code and the comments to make sure you understand what each step is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polyfit requires that NaN rows be removed\n",
    "CHEMI_df=CHEMI_df.dropna(subset=['O3_ppbv'])\n",
    "CHEMI_df=CHEMI_df.dropna(subset=['NO2_pptv'])\n",
    "\n",
    "# find the line of best fit through the data with polyfit; b gives the y-intercept and m gives the slope\n",
    "m, b = np.polyfit(CHEMI_df['NO2_pptv'], CHEMI_df['O3_ppbv'], 1)\n",
    "\n",
    "# plot the original data points as well as the line of best fit\n",
    "plt.plot(CHEMI_df['NO2_pptv'], CHEMI_df['O3_ppbv'],\".\")\n",
    "plt.plot(CHEMI_df['NO2_pptv'], b + m * CHEMI_df['O3_ppbv'], '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.4** Note that the linear regression seems to fit some of the data points alright, while other data points do not fit this linear relationship. This is because there are two distinct O<sub>3</sub>-NO<sub>2</sub> relationships represented in these datasets depending on whether the NO<sub>2</sub> mixing ratio is very low (0-150 ppt) or higher (>150 ppt). Linear regression functions tend to prioritize fitting data points with higher magnitudes, and so fail to capture relationships present at lower concentrations. In order to examine the low-NO<sub>2</sub> relationship directly, devise your own strategy to plot and fit only this subset of the data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO FIT AND PLOT LOW-NO2 DATA POINTS ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.5** Plot and fit the subset of data points with NO<sub>2</sub> > 150 ppt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE TO FIT AND PLOT HIGH-NO2 DATA POINTS ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.6** Correlate the CHEMI ozone dataset with one of the other (i.e., KACES or TDLIF) NO<sub>2</sub> datasets. Note that you will need likey need to interpolate, average, or merge the observations first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Questions.** Pair up with a partner and discuss the following:\n",
    "\n",
    "1. Compare the NO<sub>2</sub> correlations that resulted from the interpolating vs. averaging vs. merging approaches. Which approach would you recommend and why? \n",
    "2. Compare your respective approaches for eliminating O<sub>3</sub> outliers.\n",
    "    * What were the strengths and weaknesses of each? If you used the same approach as your partner, discuss another approach you could have used.\n",
    "    * How many data points did each of your strategies end up removing from the dataset?\n",
    "    * What would happen to your data analysis if your outlier definition was too aggressive (e.g., eliminated some valid data points)? What would happen to your data analysis if your outlier definition was too permissive (e.g., kept some invalid data points)?\n",
    "3. Compare the best fit O<sub>3</sub> vs. NO<sub>2</sub> lines you derived for the entire vs. just the low-NO<sub>2</sub> population of the data points. Using what you learned this morning about the NO<sub>x</sub> cycle, what is the possible chemical explanation for the sign of the slope of these lines? In there an alternative, physical explanation?\n",
    "4. What did you discover about the correlation between O<sub>3</sub> and either the KACES or TDLIF NO<sub>2</sub> observations? Were your conclusions the same as your partners? If not, discuss how your analyses differed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Enter your answer here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
